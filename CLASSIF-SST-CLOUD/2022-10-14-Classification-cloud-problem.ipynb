{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Classification: Are SST images corrupted by clouds?\n",
    "\n",
    "The purpose of this notebook is to classify SST (Sea Surface Temperature) images depending on whether they are corrupted by clouds, or not.\n",
    "\n",
    "Several methods of cloud masking have been used. It is up to you to test one network per method, and then compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys,glob\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to be modified\n",
    "path = \"./\"\n",
    "\n",
    "# load npy file\n",
    "sst_fill_10000 = np.load(path+'SST_clouds_fill_10000.npy')\n",
    "sst_fill_nan = np.load(path+'SST_clouds_fill_nan.npy')\n",
    "sst_fill_mean = np.load(path+'SST_clouds_fill_mean.npy')\n",
    "labels = np.load(path+'labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n",
    "\n",
    "The cell below plots a few samples of the three datasets loaded previously. Run it.\n",
    "\n",
    ">**QUIZZ** : \n",
    ">- How do you think these datasets were built?\n",
    ">- What do the classes 0 and 1 correspond to ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(sst_fill_10000[i,:,:],vmin=np.min(sst_fill_mean[i,:,:]),vmax=np.max(sst_fill_mean[i,:,:]),origin='lower')\n",
    "    # plt.colorbar()\n",
    "    plt.title('SST fill 10000')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(sst_fill_mean[i,:,:],vmin=np.min(sst_fill_mean[i,:,:]),vmax=np.max(sst_fill_mean[i,:,:]),origin='lower')\n",
    "    # plt.colorbar()\n",
    "    plt.title('SST fill mean')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(sst_fill_nan[i,:,:],vmin=np.min(sst_fill_mean[i,:,:]),vmax=np.max(sst_fill_mean[i,:,:]),origin='lower')\n",
    "    # plt.colorbar()\n",
    "    plt.title('SST fill nan')\n",
    "    plt.suptitle('Class : '+ str(labels[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "You are going to build a CNN to sort SST images in classes 0 and 1. The first step is to prepare the data. Here each dataset comes in one block. Shuffling the samples before separating them into the various sets needed for training and testing is useful. Below, we suggest to work with the \"10000\" dataset. You can perform experiments with the others later.\n",
    "\n",
    ">**WORK** : \n",
    ">1. Determine what is the input (X) and the output (Y).\n",
    ">2. Shuffle and split the data into relevant sets (shuffle and train_test_split functions from scikit; check the doc)\n",
    ">3. Reshape (toto.reshape) the data to pass it into the network \n",
    ">4. Normalize the data with the maximum value (replace $XXXX$. please don't fall in the trap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "X,Y=shuffle(sst_fill_10000,labels)\n",
    " \n",
    "# Split in train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Reshape\n",
    "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\n",
    "X_test=X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)\n",
    "\n",
    "# Normalize\n",
    "normalization_factor = 1/np.max(X_train)\n",
    "X_train = XXXX\n",
    "X_test = XXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Time to create the model! What kind of loss function should you use?\n",
    "\n",
    ">**WORK** :\n",
    ">1. Build, compile, and fit a CNN model \n",
    ">2. Visualize the evolution of the loss function and adjust some parameters if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Built a CNN Model\n",
    "#### Model construction with Sequential mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the activation function of the output layer is sigmoid\n",
    "model.compile(optimizer='adam',\n",
    "              loss='XXXX',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "history=model.fit(X_train,y_train,epochs=10,\n",
    "                 batch_size=32,\n",
    "                 validation_split=0.2,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Visualize the evolution of the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],'b-',label='Train loss')\n",
    "plt.plot(history.history['val_loss'], 'r-',label='Validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prediction from the model \n",
    "\n",
    ">**WORK** : \n",
    ">1. Evaluate the performance of your model with model.evaluate\n",
    ">2. Make a model prediction on test data\n",
    ">3. Visualize the results of the model prediction\n",
    ">4. Find an example for which the prediction is false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Model evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Make a model prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sigmoid = model.predict(X_test)\n",
    "#y_pred    = np.argmax(y_sigmoid, axis=-1)\n",
    "y_pred = np.rint(y_sigmoid.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Visualize the results of the model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_results=12\n",
    "n_col=4\n",
    "n_row=ceil(nb_results/n_col)\n",
    "random_results = random.sample(range(y_pred.shape[0]),k=nb_results)\n",
    "plt.figure(figsize=(16,9))\n",
    "for i,result in enumerate(random_results):\n",
    "    min_value=np.unique(np.sort(X_test[result,:,:,0]*np.max(sst_fill_10000)))[0]\n",
    "    max_value=np.unique(np.sort(X_test[result,:,:,0]*np.max(sst_fill_10000)))[-2]\n",
    "    plt.subplot(n_row,n_col,i+1)\n",
    "    plt.imshow(X_test[result,:,:,0]*np.max(sst_fill_10000),\n",
    "           vmin=min_value,vmax=max_value)\n",
    "    plt.title('pred : %i , true : %i'%(y_pred[result],y_test[result]))\n",
    "    plt.subplots_adjust(right=1,top=1)\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find an example for which the prediction is false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_false = np.where(y_pred != y_test)[0].shape[0]\n",
    "nb_test = y_pred.shape[0]\n",
    "print('There are %i false prediction(s) out of %i'%(nb_false,nb_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itmp = np.where(y_pred != y_test)[0][0]\n",
    "plt.imshow(X_test[itmp,:,:,0]*np.max(sst_fill_10000),vmin=20, vmax=30)\n",
    "plt.title('pred : %i , true : %i'%(y_pred[itmp],y_test[itmp]))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus : confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix( y_test,y_pred, normalize=None)\n",
    "    \n",
    "accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "misclass = 1 - accuracy\n",
    "\n",
    "\n",
    "cmap = plt.get_cmap('Blues')\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "# plt.title(title)\n",
    "plt.colorbar()\n",
    "\n",
    "# if target_names is not None:\n",
    "#     tick_marks = np.arange(len(target_names))\n",
    "#     plt.xticks(tick_marks, target_names, rotation=90)\n",
    "#     plt.yticks(tick_marks, target_names)\n",
    "\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "digit_format='{:0.2f}'\n",
    "\n",
    "thresh = cm.max() / 1.5 \n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "\n",
    "    plt.text(j, i, digit_format.format(cm[i, j]),\n",
    "             horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "plt.xticks(ticks=[0,1])\n",
    "plt.yticks(ticks=[0,1])\n",
    "# save_fig(save_as)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 2: Visualize the weights and bias of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_filter=model.get_layer(\"layer_conv_1\").get_weights()[0].shape[-1]\n",
    "nb_col=4\n",
    "nb_row=ceil(nb_filter/nb_col)\n",
    "fig, axes = plt.subplots(nrows=nb_row, ncols=nb_col,sharex=True,sharey=True,figsize=(16,9))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    # plt.subplot(nb_row,nb_col,i+1)\n",
    "    im=ax.imshow(model.get_layer(\"layer_conv_1\").get_weights()[0][:,:,0,i])\n",
    "    ax.set_yticks(np.arange(model.get_layer(\"layer_conv_1\").get_weights()[0].shape[1]))\n",
    "    ax.set_xticks(np.arange(model.get_layer(\"layer_conv_1\").get_weights()[0].shape[0]))\n",
    "    ax.set_title('Bias : %f'%(model.get_layer(\"layer_conv_1\").get_weights()[1][i]))\n",
    "    # plt.colorbar()\n",
    "fig.subplots_adjust(right=0.8,top=0.6)\n",
    "\n",
    "plt.colorbar(im,ax=axes.ravel().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
